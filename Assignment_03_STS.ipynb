{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_03_STS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9cL24awwZ83",
        "outputId": "fc411b44-8d29-4905-ad92-59d3bb69f7cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.8 MB 7.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 325 kB 35.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 45.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 41.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 42.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 49.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 134 kB 35.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 41.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 48.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 65.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 59.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 55.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 58.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 54.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.6 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets wandb -qq"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Team [LostCow](https://github.com/l-yohai/KLUE)의 roberta모델을 기준으로 함\n",
        "- pretrained_model : klue/roberta-base\n",
        "- tokenizer : klue/roberta-base\n",
        "- dropout : 0.1\n",
        "- batch_size : 64\n",
        "- optim : adamw_hf\n",
        "- learning_rate : 5e-5\n",
        "- loss_fnc : MSELoss"
      ],
      "metadata": {
        "id": "FrcDvF1bxgHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tarfile\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report,f1_score\n",
        "\n",
        "import torch\n",
        "from datasets import load_metric"
      ],
      "metadata": {
        "id": "rwKPDKiox4OD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU 사용 여부 확인 및 name 확인\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"# available GPUs : {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU name : {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4S4jNGEDytG",
        "outputId": "561ba7fd-e925-467b-ce3a-41e54c1d0228"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# available GPUs : 1\n",
            "GPU name : Tesla P100-PCIE-16GB\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습 및 검증 데이터 불러오기"
      ],
      "metadata": {
        "id": "-ve37vI1DcLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 다운로드\n",
        "!wget https://aistages-prod-server-public.s3.amazonaws.com/app/Competitions/000067/data/klue-sts-v1.1.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xBQEO6hD220",
        "outputId": "329c507d-5adf-4f25-ac9a-5af49a957c15"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-18 08:20:25--  https://aistages-prod-server-public.s3.amazonaws.com/app/Competitions/000067/data/klue-sts-v1.1.tar.gz\n",
            "Resolving aistages-prod-server-public.s3.amazonaws.com (aistages-prod-server-public.s3.amazonaws.com)... 52.92.195.89\n",
            "Connecting to aistages-prod-server-public.s3.amazonaws.com (aistages-prod-server-public.s3.amazonaws.com)|52.92.195.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1349881 (1.3M) [application/x-gzip]\n",
            "Saving to: ‘klue-sts-v1.1.tar.gz’\n",
            "\n",
            "klue-sts-v1.1.tar.g 100%[===================>]   1.29M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-03-18 08:20:25 (13.4 MB/s) - ‘klue-sts-v1.1.tar.gz’ saved [1349881/1349881]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 압출 풀기\n",
        "tar_bz2_file = tarfile.open(\"/content/klue-sts-v1.1.tar.gz\")\n",
        "tar_bz2_file.extractall(path=\"/content\")\n",
        "tar_bz2_file.close()"
      ],
      "metadata": {
        "id": "NOLpAFRsFMnJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습 데이터 나누기"
      ],
      "metadata": {
        "id": "SNRMh4lmGcJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train 데이터셋을 train,valid 데이터셋으로 split\n",
        "\n",
        "def read_json(file_path):\n",
        "    with open(file_path) as f:\n",
        "        return json.load(f)\n",
        "\n",
        "data=read_json('/content/klue-sts-v1.1/klue-sts-v1.1_train.json')\n",
        "\n",
        "train_length = int(len(data)*0.9)\n",
        "train = data[:train_length]\n",
        "vaild = data[train_length:]\n",
        "\n",
        "print('data_set:',len(data))\n",
        "print('train_set:',len(train),', valid_set:',len(vaild))\n",
        "\n",
        "with open('train_split.json','w') as f:\n",
        "    json.dump(train,f,ensure_ascii = False)\n",
        "    \n",
        "with open('valid_split.json','w') as f:\n",
        "    json.dump(vaild,f,ensure_ascii = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w40eFDkFVB4",
        "outputId": "ee38b7ac-383e-4677-94ba-c98496a0daf1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_set: 11668\n",
            "train_set: 10501 , valid_set: 1167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습 코드 불러오기"
      ],
      "metadata": {
        "id": "RBtKjL3vDd-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 수정한 모델 소개\n",
        "\n",
        "모델의 FClayer 층이 참고하는 roberta model의 hidden states를 다각화 하여 성능을 향상시켰습니다.\n",
        "\n",
        "base model로 선정한 LostCow team의 FClayer층의 학습 방식은 roberta model이 문장A,B에 대해서 token_type_ids 값을 입력하지 않고 구분되지 않은 상태로 학습시키며 마지막 layer의 임베딩벡터를 문장A,B의 위치를 마스킹해둔 s1_mask, s2_mask를 이용하여 분리한뒤 각 단어들의 dim의 위치값을 평균내어 하나의 토큰 임베딩 값으로 생성한 후 FClayer를 통해 연산됩니다.\n",
        "\n",
        "이 때문에 roberta model의 pooled_output을 사용하지 않으며 사용시에도 성능 향상에 기여하지 못합니다.\n",
        "\n",
        "각 문장의 임베딩 벡터의 평균값을 기준으로 FClayer의 연산이 이루어지는 점을 이용하여 각 문장의 의미가 적당하게 고려된 hidden_states layer를 탐색하여 2,3layer의 hidden_states를 추가로 concat하는 것으로 모델의 성능을 향상시켰습니다.\n",
        "\n",
        "변경 전\n",
        "```python\n",
        "  -------------------base model(model.forward code)----------------------\n",
        "        outputs = self.roberta(\n",
        "            input_ids, attention_mask=attention_mask, token_type_ids=None\n",
        "        )\n",
        "        sequence_output = outputs[0]\n",
        "        pooled_output = outputs[1]\n",
        "        s1_h = self.entity_average(sequence_output, s1_mask)\n",
        "        s2_h = self.entity_average(sequence_output, s2_mask)\n",
        "        s1_h = self.sentence_fc_layer(s1_h)\n",
        "        s2_h = self.sentence_fc_layer(s2_h)\n",
        "\n",
        "        concat_h = torch.cat([s1_h, s2_h], dim=-1)\n",
        "        concat_h = self.dense(concat_h)\n",
        "\n",
        "        logits = self.label_classifier(concat_h)\n",
        "\n",
        "        outputs = (logits,) + outputs[2:]\n",
        "```\n",
        "\n",
        "변경 후\n",
        "```python\n",
        "      ----------------custom model(model.forward code)---------------------\n",
        "\n",
        "        outputs = self.roberta(\n",
        "            input_ids, attention_mask=attention_mask, token_type_ids=None, output_hidden_states=True\n",
        "        )\n",
        "\n",
        "        sequence_output = outputs[0]\n",
        "        pooled_output = outputs[1]\n",
        "        s1_h = self.entity_average(sequence_output, s1_mask)\n",
        "        s2_h = self.entity_average(sequence_output, s2_mask)\n",
        "        s1_h = self.sentence_fc_layer(s1_h)\n",
        "        s2_h = self.sentence_fc_layer(s2_h)\n",
        "        \n",
        "        sequence_output_sec_layer=outputs['hidden_states'][2]\n",
        "        ss1_h = self.entity_average(sequence_output_sec_layer, s1_mask)\n",
        "        ss2_h = self.entity_average(sequence_output_sec_layer, s2_mask)\n",
        "        ss1_h = self.sentence_fc_layer2(ss1_h)\n",
        "        ss2_h = self.sentence_fc_layer2(ss2_h)\n",
        "\n",
        "        sequence_output_sec_layer2=outputs['hidden_states'][3]\n",
        "        sss1_h = self.entity_average(sequence_output_sec_layer2, s1_mask)\n",
        "        sss2_h = self.entity_average(sequence_output_sec_layer2, s2_mask)\n",
        "        sss1_h = self.sentence_fc_layer3(sss1_h)\n",
        "        sss2_h = self.sentence_fc_layer3(sss2_h)\n",
        "\n",
        "        concat_h = torch.cat([s1_h, s2_h,ss1_h, ss2_h,sss1_h, sss2_h], dim=-1)\n",
        "        concat_h = self.dense(concat_h)\n",
        "        concat_h = self.dense2(concat_h)\n",
        "        logits = self.label_classifier(concat_h)\n",
        "\n",
        "        outputs = (logits,) + ()\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "X2RhjdyEHocR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 파라미터 설명\n",
        "- `save_steps`을 100으로 설정한 것을 제외하곤 default 값으로 학습하였다.\n",
        "\n",
        "```python\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    # data_arg\n",
        "    parser.add_argument(\"--data_dir\", type=str, default=\"./data\")\n",
        "    parser.add_argument(\"--model_dir\", type=str, default=\"./model\")\n",
        "    parser.add_argument(\"--output_dir\", type=str, default=\"./output\")\n",
        "    parser.add_argument(\"--model_name_or_path\", type=str, default=\"klue/roberta-large\")\n",
        "    parser.add_argument(\"--train_filename\", type=str, default=\"klue-sts-v1.1_train.json\")\n",
        "    parser.add_argument(\"--valid_filename\", type=str, default=\"klue-sts-v1.1_dev.json\")\n",
        "\n",
        "    # train_arg\n",
        "    parser.add_argument(\"--num_labels\", type=int, default=1)\n",
        "    parser.add_argument(\"--seed\", type=int, default=42)\n",
        "    parser.add_argument(\"--num_train_epochs\", type=int, default=10)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=64)\n",
        "    parser.add_argument(\"--learning_rate\", type=float, default=5e-5)\n",
        "    parser.add_argument(\"--gradient_accumulation_steps\", type=int, default=1)\n",
        "    parser.add_argument(\"--weight_decay\", type=float, default=0.01)\n",
        "    parser.add_argument(\"--max_seq_length\", type=int, default=110)\n",
        "\n",
        "    # eval_arg\n",
        "    parser.add_argument(\"--evaluation_strategy\", type=str, default=\"steps\")\n",
        "    parser.add_argument(\"--save_steps\", type=int, default=250) # 100 steps\n",
        "    parser.add_argument(\"--save_total_limit\", type=int, default=2)\n",
        "\n",
        "    # wandb_log\n",
        "    parser.add_argument(\"--wandb_entity\", type=str, default='wanted_ai_06') # 수정 불필요\n",
        "    parser.add_argument(\"--wandb_project\", type=str, default='sohn_assign3') # 영어성씨_assign3로 수정할 것\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    main(args)\n",
        "```"
      ],
      "metadata": {
        "id": "VoRTOvOPIQ2V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 학습"
      ],
      "metadata": {
        "id": "h55QcBvPMAyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 수정한 모델 불러오기\n",
        "!git clone https://github.com/wanted-AI-06/Assignment-03"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g40eoYXzDZpS",
        "outputId": "5c308d28-d8e1-4db5-a4c4-9d0d2b0dc06c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Assignment-03'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 63 (delta 23), reused 44 (delta 11), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (63/63), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Assignment-03/code/train.py --data_dir /content --model_name_or_path \"klue/roberta-base\" --train_filename \"train_split.json\" --valid_filename \"valid_split.json\" --num_train_epochs 10 --save_steps 100 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6AkE8gdFg4N",
        "outputId": "4b03a5ef-32b4-4456-9652-d6825d334d41"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwanted_ai_06\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.11\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20220318_082354-3spy8l32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdaily-tree-21\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/wanted_ai_06/sohn_assign3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/wanted_ai_06/sohn_assign3/runs/3spy8l32\u001b[0m\n",
            "Downloading: 100% 546/546 [00:00<00:00, 480kB/s]\n",
            "Downloading: 100% 375/375 [00:00<00:00, 300kB/s]\n",
            "Downloading: 100% 243k/243k [00:00<00:00, 1.31MB/s]\n",
            "Downloading: 100% 734k/734k [00:00<00:00, 2.91MB/s]\n",
            "Downloading: 100% 173/173 [00:00<00:00, 131kB/s]\n",
            "Downloading: 100% 422M/422M [00:09<00:00, 48.5MB/s]\n",
            "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaForStsRegression: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias']\n",
            "- This IS expected if you are initializing RobertaForStsRegression from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForStsRegression from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForStsRegression were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'sentence_fc_layer.linear.weight', 'cls_fc_layer.linear.bias', 'embedding_vectors.linear.bias', 'sentence_fc_layer2.linear.weight', 'sentence_fc_layer3.linear.bias', 'sentence_fc_layer2.linear.bias', 'dense.linear.bias', 'sentence_fc_layer3.linear.weight', 'dense2.linear.weight', 'cls_fc_layer.linear.weight', 'dense.linear.weight', 'sentence_fc_layer.linear.bias', 'label_classifier.linear.weight', 'dense2.linear.bias', 'label_classifier.linear.bias', 'roberta.pooler.dense.weight', 'embedding_vectors.linear.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using amp half precision backend\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 10501\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1650\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "  6% 100/1650 [01:18<24:34,  1.05it/s]{'loss': 1.1387, 'learning_rate': 4.709090909090909e-05, 'epoch': 0.61}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1167\n",
            "  Batch size = 64\n",
            "\n",
            "  0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/19 [00:00<00:02,  7.75it/s]\u001b[A\n",
            " 16% 3/19 [00:00<00:02,  5.44it/s]\u001b[A\n",
            " 21% 4/19 [00:00<00:03,  4.75it/s]\u001b[A\n",
            " 26% 5/19 [00:01<00:03,  4.39it/s]\u001b[A\n",
            " 32% 6/19 [00:01<00:03,  4.18it/s]\u001b[A\n",
            " 37% 7/19 [00:01<00:02,  4.06it/s]\u001b[A\n",
            " 42% 8/19 [00:01<00:02,  3.98it/s]\u001b[A\n",
            " 47% 9/19 [00:02<00:02,  3.95it/s]\u001b[A\n",
            " 53% 10/19 [00:02<00:02,  3.93it/s]\u001b[A\n",
            " 58% 11/19 [00:02<00:02,  3.92it/s]\u001b[A\n",
            " 63% 12/19 [00:02<00:01,  3.89it/s]\u001b[A\n",
            " 68% 13/19 [00:03<00:01,  3.88it/s]\u001b[A\n",
            " 74% 14/19 [00:03<00:01,  3.88it/s]\u001b[A\n",
            " 79% 15/19 [00:03<00:01,  3.87it/s]\u001b[A\n",
            " 84% 16/19 [00:03<00:00,  3.88it/s]\u001b[A\n",
            " 89% 17/19 [00:04<00:00,  3.87it/s]\u001b[A\n",
            " 95% 18/19 [00:04<00:00,  3.87it/s]\u001b[A\n",
            "\n",
            "Downloading builder script: 3.85kB [00:00, 3.10MB/s]       \n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.3972676992416382, 'eval_pearsonr': 0.950666728037494, 'eval_runtime': 5.3187, 'eval_samples_per_second': 219.414, 'eval_steps_per_second': 3.572, 'epoch': 0.61}\n",
            "  6% 100/1650 [01:24<24:34,  1.05it/s]\n",
            "100% 19/19 [00:05<00:00,  3.87it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to ./model/checkpoint-100\n",
            "Configuration saved in ./model/checkpoint-100/config.json\n",
            "Model weights saved in ./model/checkpoint-100/pytorch_model.bin\n",
            " 12% 200/1650 [02:47<22:38,  1.07it/s]***** Running Evaluation *****\n",
            "  Num examples = 1167\n",
            "  Batch size = 64\n",
            "{'loss': 0.2421, 'learning_rate': 4.406060606060606e-05, 'epoch': 1.21}\n",
            "\n",
            "  0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/19 [00:00<00:02,  7.72it/s]\u001b[A\n",
            " 16% 3/19 [00:00<00:02,  5.42it/s]\u001b[A\n",
            " 21% 4/19 [00:00<00:03,  4.71it/s]\u001b[A\n",
            " 26% 5/19 [00:01<00:03,  4.36it/s]\u001b[A\n",
            " 32% 6/19 [00:01<00:03,  4.19it/s]\u001b[A\n",
            " 37% 7/19 [00:01<00:02,  4.08it/s]\u001b[A\n",
            " 42% 8/19 [00:01<00:02,  4.03it/s]\u001b[A\n",
            " 47% 9/19 [00:02<00:02,  3.98it/s]\u001b[A\n",
            " 53% 10/19 [00:02<00:02,  3.96it/s]\u001b[A\n",
            " 58% 11/19 [00:02<00:02,  3.93it/s]\u001b[A\n",
            " 63% 12/19 [00:02<00:01,  3.92it/s]\u001b[A\n",
            " 68% 13/19 [00:03<00:01,  3.91it/s]\u001b[A\n",
            " 74% 14/19 [00:03<00:01,  3.89it/s]\u001b[A\n",
            " 79% 15/19 [00:03<00:01,  3.89it/s]\u001b[A\n",
            " 84% 16/19 [00:03<00:00,  3.90it/s]\u001b[A\n",
            " 89% 17/19 [00:04<00:00,  3.90it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.366609662771225, 'eval_pearsonr': 0.9508796915045706, 'eval_runtime': 5.0859, 'eval_samples_per_second': 229.456, 'eval_steps_per_second': 3.736, 'epoch': 1.21}\n",
            " 12% 200/1650 [02:52<22:38,  1.07it/s]\n",
            "100% 19/19 [00:04<00:00,  3.90it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to ./model/checkpoint-200\n",
            "Configuration saved in ./model/checkpoint-200/config.json\n",
            "Model weights saved in ./model/checkpoint-200/pytorch_model.bin\n",
            "{'loss': 0.1754, 'learning_rate': 4.103030303030303e-05, 'epoch': 1.82}\n",
            " 18% 300/1650 [04:15<21:19,  1.05it/s]***** Running Evaluation *****\n",
            "  Num examples = 1167\n",
            "  Batch size = 64\n",
            "\n",
            "  0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/19 [00:00<00:02,  7.71it/s]\u001b[A\n",
            " 16% 3/19 [00:00<00:02,  5.45it/s]\u001b[A\n",
            " 21% 4/19 [00:00<00:03,  4.71it/s]\u001b[A\n",
            " 26% 5/19 [00:01<00:03,  4.37it/s]\u001b[A\n",
            " 32% 6/19 [00:01<00:03,  4.18it/s]\u001b[A\n",
            " 37% 7/19 [00:01<00:02,  4.08it/s]\u001b[A\n",
            " 42% 8/19 [00:01<00:02,  4.00it/s]\u001b[A\n",
            " 47% 9/19 [00:02<00:02,  3.97it/s]\u001b[A\n",
            " 53% 10/19 [00:02<00:02,  3.92it/s]\u001b[A\n",
            " 58% 11/19 [00:02<00:02,  3.90it/s]\u001b[A\n",
            " 63% 12/19 [00:02<00:01,  3.88it/s]\u001b[A\n",
            " 68% 13/19 [00:03<00:01,  3.88it/s]\u001b[A\n",
            " 74% 14/19 [00:03<00:01,  3.87it/s]\u001b[A\n",
            " 79% 15/19 [00:03<00:01,  3.87it/s]\u001b[A\n",
            " 84% 16/19 [00:03<00:00,  3.87it/s]\u001b[A\n",
            " 89% 17/19 [00:04<00:00,  3.86it/s]\u001b[A\n",
            "                                      \n",
            "{'eval_loss': 0.32836365699768066, 'eval_pearsonr': 0.9565973881218245, 'eval_runtime': 5.1018, 'eval_samples_per_second': 228.741, 'eval_steps_per_second': 3.724, 'epoch': 1.82}\n",
            " 18% 300/1650 [04:20<21:19,  1.05it/s]\n",
            "100% 19/19 [00:04<00:00,  3.85it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to ./model/checkpoint-300\n",
            "Configuration saved in ./model/checkpoint-300/config.json\n",
            "Model weights saved in ./model/checkpoint-300/pytorch_model.bin\n",
            "Deleting older checkpoint [model/checkpoint-100] due to args.save_total_limit\n",
            " 24% 400/1650 [05:43<19:59,  1.04it/s]{'loss': 0.1357, 'learning_rate': 3.8e-05, 'epoch': 2.42}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1167\n",
            "  Batch size = 64\n",
            "\n",
            "  0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/19 [00:00<00:02,  7.75it/s]\u001b[A\n",
            " 16% 3/19 [00:00<00:02,  5.41it/s]\u001b[A\n",
            " 21% 4/19 [00:00<00:03,  4.70it/s]\u001b[A\n",
            " 26% 5/19 [00:01<00:03,  4.38it/s]\u001b[A\n",
            " 32% 6/19 [00:01<00:03,  4.21it/s]\u001b[A\n",
            " 37% 7/19 [00:01<00:02,  4.07it/s]\u001b[A\n",
            " 42% 8/19 [00:01<00:02,  4.00it/s]\u001b[A\n",
            " 47% 9/19 [00:02<00:02,  3.96it/s]\u001b[A\n",
            " 53% 10/19 [00:02<00:02,  3.91it/s]\u001b[A\n",
            " 58% 11/19 [00:02<00:02,  3.89it/s]\u001b[A\n",
            " 63% 12/19 [00:02<00:01,  3.89it/s]\u001b[A\n",
            " 68% 13/19 [00:03<00:01,  3.90it/s]\u001b[A\n",
            " 74% 14/19 [00:03<00:01,  3.89it/s]\u001b[A\n",
            " 79% 15/19 [00:03<00:01,  3.88it/s]\u001b[A\n",
            " 84% 16/19 [00:03<00:00,  3.88it/s]\u001b[A\n",
            " 89% 17/19 [00:04<00:00,  3.86it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.35583218932151794, 'eval_pearsonr': 0.9547279046766726, 'eval_runtime': 5.105, 'eval_samples_per_second': 228.598, 'eval_steps_per_second': 3.722, 'epoch': 2.42}\n",
            " 24% 400/1650 [05:48<19:59,  1.04it/s]\n",
            "100% 19/19 [00:04<00:00,  3.84it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to ./model/checkpoint-400\n",
            "Configuration saved in ./model/checkpoint-400/config.json\n",
            "Model weights saved in ./model/checkpoint-400/pytorch_model.bin\n",
            "Deleting older checkpoint [model/checkpoint-200] due to args.save_total_limit\n",
            " 30% 500/1650 [07:11<17:37,  1.09it/s]{'loss': 0.1194, 'learning_rate': 3.4969696969696966e-05, 'epoch': 3.03}\n",
            " 30% 500/1650 [07:11<17:37,  1.09it/s]***** Running Evaluation *****\n",
            "  Num examples = 1167\n",
            "  Batch size = 64\n",
            "\n",
            "  0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/19 [00:00<00:02,  7.75it/s]\u001b[A\n",
            " 16% 3/19 [00:00<00:02,  5.48it/s]\u001b[A\n",
            " 21% 4/19 [00:00<00:03,  4.76it/s]\u001b[A\n",
            " 26% 5/19 [00:01<00:03,  4.41it/s]\u001b[A\n",
            " 32% 6/19 [00:01<00:03,  4.23it/s]\u001b[A\n",
            " 37% 7/19 [00:01<00:02,  4.11it/s]\u001b[A\n",
            " 42% 8/19 [00:01<00:02,  4.03it/s]\u001b[A\n",
            " 47% 9/19 [00:02<00:02,  3.98it/s]\u001b[A\n",
            " 53% 10/19 [00:02<00:02,  3.94it/s]\u001b[A\n",
            " 58% 11/19 [00:02<00:02,  3.91it/s]\u001b[A\n",
            " 63% 12/19 [00:02<00:01,  3.89it/s]\u001b[A\n",
            " 68% 13/19 [00:03<00:01,  3.89it/s]\u001b[A\n",
            " 74% 14/19 [00:03<00:01,  3.88it/s]\u001b[A\n",
            " 79% 15/19 [00:03<00:01,  3.88it/s]\u001b[A\n",
            " 84% 16/19 [00:03<00:00,  3.87it/s]\u001b[A\n",
            " 89% 17/19 [00:04<00:00,  3.88it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.2424973100423813, 'eval_pearsonr': 0.9586758780788309, 'eval_runtime': 5.2329, 'eval_samples_per_second': 223.013, 'eval_steps_per_second': 3.631, 'epoch': 3.03}\n",
            " 30% 500/1650 [07:17<17:37,  1.09it/s]\n",
            "100% 19/19 [00:04<00:00,  3.88it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to ./model/checkpoint-500\n",
            "Configuration saved in ./model/checkpoint-500/config.json\n",
            "Model weights saved in ./model/checkpoint-500/pytorch_model.bin\n",
            "Deleting older checkpoint [model/checkpoint-300] due to args.save_total_limit\n",
            "{'loss': 0.093, 'learning_rate': 3.1939393939393944e-05, 'epoch': 3.64}\n",
            " 36% 600/1650 [08:40<16:28,  1.06it/s]***** Running Evaluation *****\n",
            "  Num examples = 1167\n",
            "  Batch size = 64\n",
            "\n",
            "  0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/19 [00:00<00:02,  7.74it/s]\u001b[A\n",
            " 16% 3/19 [00:00<00:02,  5.45it/s]\u001b[A\n",
            " 21% 4/19 [00:00<00:03,  4.73it/s]\u001b[A\n",
            " 26% 5/19 [00:01<00:03,  4.38it/s]\u001b[A\n",
            " 32% 6/19 [00:01<00:03,  4.20it/s]\u001b[A\n",
            " 37% 7/19 [00:01<00:02,  4.09it/s]\u001b[A\n",
            " 42% 8/19 [00:01<00:02,  4.03it/s]\u001b[A\n",
            " 47% 9/19 [00:02<00:02,  3.98it/s]\u001b[A\n",
            " 53% 10/19 [00:02<00:02,  3.95it/s]\u001b[A\n",
            " 58% 11/19 [00:02<00:02,  3.93it/s]\u001b[A\n",
            " 63% 12/19 [00:02<00:01,  3.92it/s]\u001b[A\n",
            " 68% 13/19 [00:03<00:01,  3.91it/s]\u001b[A\n",
            " 74% 14/19 [00:03<00:01,  3.90it/s]\u001b[A\n",
            " 79% 15/19 [00:03<00:01,  3.90it/s]\u001b[A\n",
            " 84% 16/19 [00:03<00:00,  3.89it/s]\u001b[A\n",
            " 89% 17/19 [00:04<00:00,  3.90it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.28982171416282654, 'eval_pearsonr': 0.9595658120451372, 'eval_runtime': 5.0758, 'eval_samples_per_second': 229.916, 'eval_steps_per_second': 3.743, 'epoch': 3.64}\n",
            " 36% 600/1650 [08:45<16:28,  1.06it/s]\n",
            "100% 19/19 [00:04<00:00,  3.90it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to ./model/checkpoint-600\n",
            "Configuration saved in ./model/checkpoint-600/config.json\n",
            "Model weights saved in ./model/checkpoint-600/pytorch_model.bin\n",
            "Deleting older checkpoint [model/checkpoint-400] due to args.save_total_limit\n",
            "{'loss': 0.083, 'learning_rate': 2.8909090909090908e-05, 'epoch': 4.24}\n",
            " 42% 700/1650 [10:08<14:52,  1.06it/s]***** Running Evaluation *****\n",
            "  Num examples = 1167\n",
            "  Batch size = 64\n",
            "\n",
            "  0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/19 [00:00<00:02,  7.79it/s]\u001b[A\n",
            " 16% 3/19 [00:00<00:02,  5.45it/s]\u001b[A\n",
            " 21% 4/19 [00:00<00:03,  4.72it/s]\u001b[A\n",
            " 26% 5/19 [00:01<00:03,  4.37it/s]\u001b[A\n",
            " 32% 6/19 [00:01<00:03,  4.19it/s]\u001b[A\n",
            " 37% 7/19 [00:01<00:02,  4.09it/s]\u001b[A\n",
            " 42% 8/19 [00:01<00:02,  4.03it/s]\u001b[A\n",
            " 47% 9/19 [00:02<00:02,  3.99it/s]\u001b[A\n",
            " 53% 10/19 [00:02<00:02,  3.97it/s]\u001b[A\n",
            " 58% 11/19 [00:02<00:02,  3.95it/s]\u001b[A\n",
            " 63% 12/19 [00:02<00:01,  3.93it/s]\u001b[A\n",
            " 68% 13/19 [00:03<00:01,  3.90it/s]\u001b[A\n",
            " 74% 14/19 [00:03<00:01,  3.89it/s]\u001b[A\n",
            " 79% 15/19 [00:03<00:01,  3.88it/s]\u001b[A\n",
            " 84% 16/19 [00:03<00:00,  3.88it/s]\u001b[A\n",
            " 89% 17/19 [00:04<00:00,  3.88it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.2540854811668396, 'eval_pearsonr': 0.9587223138658242, 'eval_runtime': 5.0748, 'eval_samples_per_second': 229.959, 'eval_steps_per_second': 3.744, 'epoch': 4.24}\n",
            " 42% 700/1650 [10:13<14:52,  1.06it/s]\n",
            "100% 19/19 [00:04<00:00,  3.88it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to ./model/checkpoint-700\n",
            "Configuration saved in ./model/checkpoint-700/config.json\n",
            "Model weights saved in ./model/checkpoint-700/pytorch_model.bin\n",
            "Deleting older checkpoint [model/checkpoint-500] due to args.save_total_limit\n",
            " 48% 800/1650 [11:36<13:12,  1.07it/s]{'loss': 0.0677, 'learning_rate': 2.587878787878788e-05, 'epoch': 4.85}\n",
            " 48% 800/1650 [11:36<13:12,  1.07it/s]***** Running Evaluation *****\n",
            "  Num examples = 1167\n",
            "  Batch size = 64\n",
            "\n",
            "  0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/19 [00:00<00:02,  7.76it/s]\u001b[A\n",
            " 16% 3/19 [00:00<00:02,  5.45it/s]\u001b[A\n",
            " 21% 4/19 [00:00<00:03,  4.72it/s]\u001b[A\n",
            " 26% 5/19 [00:01<00:03,  4.38it/s]\u001b[A\n",
            " 32% 6/19 [00:01<00:03,  4.20it/s]\u001b[A\n",
            " 37% 7/19 [00:01<00:02,  4.08it/s]\u001b[A\n",
            " 42% 8/19 [00:01<00:02,  4.01it/s]\u001b[A\n",
            " 47% 9/19 [00:02<00:02,  3.96it/s]\u001b[A\n",
            " 53% 10/19 [00:02<00:02,  3.93it/s]\u001b[A\n",
            " 58% 11/19 [00:02<00:02,  3.92it/s]\u001b[A\n",
            " 63% 12/19 [00:02<00:01,  3.91it/s]\u001b[A\n",
            " 68% 13/19 [00:03<00:01,  3.90it/s]\u001b[A\n",
            " 74% 14/19 [00:03<00:01,  3.88it/s]\u001b[A\n",
            " 79% 15/19 [00:03<00:01,  3.88it/s]\u001b[A\n",
            " 84% 16/19 [00:03<00:00,  3.89it/s]\u001b[A\n",
            " 89% 17/19 [00:04<00:00,  3.89it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.2683432102203369, 'eval_pearsonr': 0.9595898286179911, 'eval_runtime': 5.1366, 'eval_samples_per_second': 227.192, 'eval_steps_per_second': 3.699, 'epoch': 4.85}\n",
            " 48% 800/1650 [11:41<13:12,  1.07it/s]\n",
            "100% 19/19 [00:04<00:00,  3.88it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to ./model/checkpoint-800\n",
            "Configuration saved in ./model/checkpoint-800/config.json\n",
            "Model weights saved in ./model/checkpoint-800/pytorch_model.bin\n",
            "Deleting older checkpoint [model/checkpoint-600] due to args.save_total_limit\n",
            " 55% 900/1650 [13:03<11:50,  1.06it/s]{'loss': 0.0577, 'learning_rate': 2.284848484848485e-05, 'epoch': 5.45}\n",
            " 55% 900/1650 [13:03<11:50,  1.06it/s]***** Running Evaluation *****\n",
            "  Num examples = 1167\n",
            "  Batch size = 64\n",
            "\n",
            "  0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/19 [00:00<00:02,  7.76it/s]\u001b[A\n",
            " 16% 3/19 [00:00<00:02,  5.48it/s]\u001b[A\n",
            " 21% 4/19 [00:00<00:03,  4.75it/s]\u001b[A\n",
            " 26% 5/19 [00:01<00:03,  4.42it/s]\u001b[A\n",
            " 32% 6/19 [00:01<00:03,  4.22it/s]\u001b[A\n",
            " 37% 7/19 [00:01<00:02,  4.10it/s]\u001b[A\n",
            " 42% 8/19 [00:01<00:02,  4.03it/s]\u001b[A\n",
            " 47% 9/19 [00:02<00:02,  3.97it/s]\u001b[A\n",
            " 53% 10/19 [00:02<00:02,  3.93it/s]\u001b[A\n",
            " 58% 11/19 [00:02<00:02,  3.90it/s]\u001b[A\n",
            " 63% 12/19 [00:02<00:01,  3.90it/s]\u001b[A\n",
            " 68% 13/19 [00:03<00:01,  3.88it/s]\u001b[A\n",
            " 74% 14/19 [00:03<00:01,  3.89it/s]\u001b[A\n",
            " 79% 15/19 [00:03<00:01,  3.89it/s]\u001b[A\n",
            " 84% 16/19 [00:03<00:00,  3.89it/s]\u001b[A\n",
            " 89% 17/19 [00:04<00:00,  3.89it/s]\u001b[A\n",
            "                                      \n",
            "                                   {'eval_loss': 0.2500363886356354, 'eval_pearsonr': 0.9601290500078997, 'eval_runtime': 5.237, 'eval_samples_per_second': 222.837, 'eval_steps_per_second': 3.628, 'epoch': 5.45}\n",
            " 55% 900/1650 [13:09<11:50,  1.06it/s]\n",
            "100% 19/19 [00:04<00:00,  3.89it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to ./model/checkpoint-900\n",
            "Configuration saved in ./model/checkpoint-900/config.json\n",
            "Model weights saved in ./model/checkpoint-900/pytorch_model.bin\n",
            "Deleting older checkpoint [model/checkpoint-700] due to args.save_total_limit\n",
            "{'loss': 0.054, 'learning_rate': 1.981818181818182e-05, 'epoch': 6.06}\n",
            " 61% 1000/1650 [14:31<10:14,  1.06it/s]***** Running Evaluation *****\n",
            "  Num examples = 1167\n",
            "  Batch size = 64\n",
            "\n",
            "  0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/19 [00:00<00:02,  7.74it/s]\u001b[A\n",
            " 16% 3/19 [00:00<00:02,  5.46it/s]\u001b[A\n",
            " 21% 4/19 [00:00<00:03,  4.75it/s]\u001b[A\n",
            " 26% 5/19 [00:01<00:03,  4.41it/s]\u001b[A\n",
            " 32% 6/19 [00:01<00:03,  4.22it/s]\u001b[A\n",
            " 37% 7/19 [00:01<00:02,  4.10it/s]\u001b[A\n",
            " 42% 8/19 [00:01<00:02,  4.03it/s]\u001b[A\n",
            " 47% 9/19 [00:02<00:02,  3.98it/s]\u001b[A\n",
            " 53% 10/19 [00:02<00:02,  3.93it/s]\u001b[A\n",
            " 58% 11/19 [00:02<00:02,  3.92it/s]\u001b[A\n",
            " 63% 12/19 [00:02<00:01,  3.89it/s]\u001b[A\n",
            " 68% 13/19 [00:03<00:01,  3.89it/s]\u001b[A\n",
            " 74% 14/19 [00:03<00:01,  3.89it/s]\u001b[A\n",
            " 79% 15/19 [00:03<00:01,  3.88it/s]\u001b[A\n",
            " 84% 16/19 [00:03<00:00,  3.89it/s]\u001b[A\n",
            " 89% 17/19 [00:04<00:00,  3.89it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.2727000415325165, 'eval_pearsonr': 0.9586247268368471, 'eval_runtime': 5.0981, 'eval_samples_per_second': 228.908, 'eval_steps_per_second': 3.727, 'epoch': 6.06}\n",
            " 61% 1000/1650 [14:36<10:14,  1.06it/s]\n",
            "100% 19/19 [00:04<00:00,  3.89it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to ./model/checkpoint-1000\n",
            "Configuration saved in ./model/checkpoint-1000/config.json\n",
            "Model weights saved in ./model/checkpoint-1000/pytorch_model.bin\n",
            "Deleting older checkpoint [model/checkpoint-800] due to args.save_total_limit\n",
            " 67% 1100/1650 [15:59<08:35,  1.07it/s]{'loss': 0.0434, 'learning_rate': 1.6787878787878787e-05, 'epoch': 6.67}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1167\n",
            "  Batch size = 64\n",
            "\n",
            "  0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/19 [00:00<00:02,  7.80it/s]\u001b[A\n",
            " 16% 3/19 [00:00<00:02,  5.50it/s]\u001b[A\n",
            " 21% 4/19 [00:00<00:03,  4.77it/s]\u001b[A\n",
            " 26% 5/19 [00:01<00:03,  4.43it/s]\u001b[A\n",
            " 32% 6/19 [00:01<00:03,  4.22it/s]\u001b[A\n",
            " 37% 7/19 [00:01<00:02,  4.09it/s]\u001b[A\n",
            " 42% 8/19 [00:01<00:02,  3.99it/s]\u001b[A\n",
            " 47% 9/19 [00:02<00:02,  3.96it/s]\u001b[A\n",
            " 53% 10/19 [00:02<00:02,  3.93it/s]\u001b[A\n",
            " 58% 11/19 [00:02<00:02,  3.92it/s]\u001b[A\n",
            " 63% 12/19 [00:02<00:01,  3.89it/s]\u001b[A\n",
            " 68% 13/19 [00:03<00:01,  3.88it/s]\u001b[A\n",
            " 74% 14/19 [00:03<00:01,  3.87it/s]\u001b[A\n",
            " 79% 15/19 [00:03<00:01,  3.87it/s]\u001b[A\n",
            " 84% 16/19 [00:03<00:00,  3.85it/s]\u001b[A\n",
            " 89% 17/19 [00:04<00:00,  3.86it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.21082162857055664, 'eval_pearsonr': 0.9625535705769546, 'eval_runtime': 5.0992, 'eval_samples_per_second': 228.858, 'eval_steps_per_second': 3.726, 'epoch': 6.67}\n",
            " 67% 1100/1650 [16:04<08:35,  1.07it/s]\n",
            "100% 19/19 [00:04<00:00,  3.86it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to ./model/checkpoint-1100\n",
            "Configuration saved in ./model/checkpoint-1100/config.json\n",
            "Model weights saved in ./model/checkpoint-1100/pytorch_model.bin\n",
            "Deleting older checkpoint [model/checkpoint-900] due to args.save_total_limit\n",
            " 73% 1200/1650 [17:27<07:06,  1.06it/s]***** Running Evaluation *****\n",
            "  Num examples = 1167\n",
            "  Batch size = 64\n",
            "{'loss': 0.0425, 'learning_rate': 1.3757575757575758e-05, 'epoch': 7.27}\n",
            "\n",
            "  0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/19 [00:00<00:02,  7.67it/s]\u001b[A\n",
            " 16% 3/19 [00:00<00:02,  5.47it/s]\u001b[A\n",
            " 21% 4/19 [00:00<00:03,  4.75it/s]\u001b[A\n",
            " 26% 5/19 [00:01<00:03,  4.37it/s]\u001b[A\n",
            " 32% 6/19 [00:01<00:03,  4.18it/s]\u001b[A\n",
            " 37% 7/19 [00:01<00:02,  4.07it/s]\u001b[A\n",
            " 42% 8/19 [00:01<00:02,  4.01it/s]\u001b[A\n",
            " 47% 9/19 [00:02<00:02,  3.95it/s]\u001b[A\n",
            " 53% 10/19 [00:02<00:02,  3.85it/s]\u001b[A\n",
            " 58% 11/19 [00:02<00:02,  3.81it/s]\u001b[A\n",
            " 63% 12/19 [00:02<00:01,  3.81it/s]\u001b[A\n",
            " 68% 13/19 [00:03<00:01,  3.81it/s]\u001b[A\n",
            " 74% 14/19 [00:03<00:01,  3.80it/s]\u001b[A\n",
            " 79% 15/19 [00:03<00:01,  3.80it/s]\u001b[A\n",
            " 84% 16/19 [00:03<00:00,  3.77it/s]\u001b[A\n",
            " 89% 17/19 [00:04<00:00,  3.75it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.22362491488456726, 'eval_pearsonr': 0.959672129563923, 'eval_runtime': 5.1864, 'eval_samples_per_second': 225.013, 'eval_steps_per_second': 3.663, 'epoch': 7.27}\n",
            " 73% 1200/1650 [17:32<07:06,  1.06it/s]\n",
            "100% 19/19 [00:04<00:00,  3.76it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to ./model/checkpoint-1200\n",
            "Configuration saved in ./model/checkpoint-1200/config.json\n",
            "Model weights saved in ./model/checkpoint-1200/pytorch_model.bin\n",
            "Deleting older checkpoint [model/checkpoint-1000] due to args.save_total_limit\n",
            " 79% 1300/1650 [18:57<05:27,  1.07it/s]***** Running Evaluation *****\n",
            "  Num examples = 1167\n",
            "  Batch size = 64\n",
            "{'loss': 0.0361, 'learning_rate': 1.0727272727272727e-05, 'epoch': 7.88}\n",
            "\n",
            "  0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/19 [00:00<00:02,  7.80it/s]\u001b[A\n",
            " 16% 3/19 [00:00<00:02,  5.49it/s]\u001b[A\n",
            " 21% 4/19 [00:00<00:03,  4.74it/s]\u001b[A\n",
            " 26% 5/19 [00:01<00:03,  4.40it/s]\u001b[A\n",
            " 32% 6/19 [00:01<00:03,  4.21it/s]\u001b[A\n",
            " 37% 7/19 [00:01<00:02,  4.09it/s]\u001b[A\n",
            " 42% 8/19 [00:01<00:02,  4.02it/s]\u001b[A\n",
            " 47% 9/19 [00:02<00:02,  3.98it/s]\u001b[A\n",
            " 53% 10/19 [00:02<00:02,  3.94it/s]\u001b[A\n",
            " 58% 11/19 [00:02<00:02,  3.92it/s]\u001b[A\n",
            " 63% 12/19 [00:02<00:01,  3.90it/s]\u001b[A\n",
            " 68% 13/19 [00:03<00:01,  3.88it/s]\u001b[A\n",
            " 74% 14/19 [00:03<00:01,  3.88it/s]\u001b[A\n",
            " 79% 15/19 [00:03<00:01,  3.87it/s]\u001b[A\n",
            " 84% 16/19 [00:03<00:00,  3.87it/s]\u001b[A\n",
            " 89% 17/19 [00:04<00:00,  3.87it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.23936671018600464, 'eval_pearsonr': 0.9607902470472457, 'eval_runtime': 5.2171, 'eval_samples_per_second': 223.686, 'eval_steps_per_second': 3.642, 'epoch': 7.88}\n",
            " 79% 1300/1650 [19:02<05:27,  1.07it/s]\n",
            "100% 19/19 [00:04<00:00,  3.88it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to ./model/checkpoint-1300\n",
            "Configuration saved in ./model/checkpoint-1300/config.json\n",
            "Model weights saved in ./model/checkpoint-1300/pytorch_model.bin\n",
            "Deleting older checkpoint [model/checkpoint-1200] due to args.save_total_limit\n",
            " 85% 1400/1650 [20:25<03:55,  1.06it/s]***** Running Evaluation *****\n",
            "  Num examples = 1167\n",
            "  Batch size = 64\n",
            "{'loss': 0.0315, 'learning_rate': 7.696969696969696e-06, 'epoch': 8.48}\n",
            "\n",
            "  0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/19 [00:00<00:02,  7.70it/s]\u001b[A\n",
            " 16% 3/19 [00:00<00:02,  5.45it/s]\u001b[A\n",
            " 21% 4/19 [00:00<00:03,  4.73it/s]\u001b[A\n",
            " 26% 5/19 [00:01<00:03,  4.38it/s]\u001b[A\n",
            " 32% 6/19 [00:01<00:03,  4.17it/s]\u001b[A\n",
            " 37% 7/19 [00:01<00:02,  4.06it/s]\u001b[A\n",
            " 42% 8/19 [00:01<00:02,  3.99it/s]\u001b[A\n",
            " 47% 9/19 [00:02<00:02,  3.94it/s]\u001b[A\n",
            " 53% 10/19 [00:02<00:02,  3.91it/s]\u001b[A\n",
            " 58% 11/19 [00:02<00:02,  3.90it/s]\u001b[A\n",
            " 63% 12/19 [00:02<00:01,  3.89it/s]\u001b[A\n",
            " 68% 13/19 [00:03<00:01,  3.88it/s]\u001b[A\n",
            " 74% 14/19 [00:03<00:01,  3.88it/s]\u001b[A\n",
            " 79% 15/19 [00:03<00:01,  3.88it/s]\u001b[A\n",
            " 84% 16/19 [00:03<00:00,  3.87it/s]\u001b[A\n",
            " 89% 17/19 [00:04<00:00,  3.85it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.22051690518856049, 'eval_pearsonr': 0.9617835242966644, 'eval_runtime': 5.1098, 'eval_samples_per_second': 228.385, 'eval_steps_per_second': 3.718, 'epoch': 8.48}\n",
            " 85% 1400/1650 [20:30<03:55,  1.06it/s]\n",
            "100% 19/19 [00:04<00:00,  3.85it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to ./model/checkpoint-1400\n",
            "Configuration saved in ./model/checkpoint-1400/config.json\n",
            "Model weights saved in ./model/checkpoint-1400/pytorch_model.bin\n",
            "Deleting older checkpoint [model/checkpoint-1300] due to args.save_total_limit\n",
            " 91% 1500/1650 [21:53<02:21,  1.06it/s]***** Running Evaluation *****\n",
            "  Num examples = 1167\n",
            "  Batch size = 64\n",
            "{'loss': 0.0284, 'learning_rate': 4.666666666666667e-06, 'epoch': 9.09}\n",
            "\n",
            "  0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/19 [00:00<00:02,  7.80it/s]\u001b[A\n",
            " 16% 3/19 [00:00<00:02,  5.50it/s]\u001b[A\n",
            " 21% 4/19 [00:00<00:03,  4.74it/s]\u001b[A\n",
            " 26% 5/19 [00:01<00:03,  4.39it/s]\u001b[A\n",
            " 32% 6/19 [00:01<00:03,  4.21it/s]\u001b[A\n",
            " 37% 7/19 [00:01<00:02,  4.09it/s]\u001b[A\n",
            " 42% 8/19 [00:01<00:02,  4.02it/s]\u001b[A\n",
            " 47% 9/19 [00:02<00:02,  3.98it/s]\u001b[A\n",
            " 53% 10/19 [00:02<00:02,  3.95it/s]\u001b[A\n",
            " 58% 11/19 [00:02<00:02,  3.93it/s]\u001b[A\n",
            " 63% 12/19 [00:02<00:01,  3.91it/s]\u001b[A\n",
            " 68% 13/19 [00:03<00:01,  3.91it/s]\u001b[A\n",
            " 74% 14/19 [00:03<00:01,  3.90it/s]\u001b[A\n",
            " 79% 15/19 [00:03<00:01,  3.90it/s]\u001b[A\n",
            " 84% 16/19 [00:03<00:00,  3.89it/s]\u001b[A\n",
            " 89% 17/19 [00:04<00:00,  3.89it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.22420917451381683, 'eval_pearsonr': 0.960997511103577, 'eval_runtime': 5.0957, 'eval_samples_per_second': 229.018, 'eval_steps_per_second': 3.729, 'epoch': 9.09}\n",
            " 91% 1500/1650 [21:58<02:21,  1.06it/s]\n",
            "100% 19/19 [00:04<00:00,  3.89it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to ./model/checkpoint-1500\n",
            "Configuration saved in ./model/checkpoint-1500/config.json\n",
            "Model weights saved in ./model/checkpoint-1500/pytorch_model.bin\n",
            "Deleting older checkpoint [model/checkpoint-1400] due to args.save_total_limit\n",
            " 97% 1600/1650 [23:22<00:47,  1.06it/s]***** Running Evaluation *****\n",
            "  Num examples = 1167\n",
            "  Batch size = 64\n",
            "{'loss': 0.0257, 'learning_rate': 1.6363636363636367e-06, 'epoch': 9.7}\n",
            "\n",
            "  0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 2/19 [00:00<00:02,  7.76it/s]\u001b[A\n",
            " 16% 3/19 [00:00<00:02,  5.49it/s]\u001b[A\n",
            " 21% 4/19 [00:00<00:03,  4.75it/s]\u001b[A\n",
            " 26% 5/19 [00:01<00:03,  4.40it/s]\u001b[A\n",
            " 32% 6/19 [00:01<00:03,  4.22it/s]\u001b[A\n",
            " 37% 7/19 [00:01<00:02,  4.11it/s]\u001b[A\n",
            " 42% 8/19 [00:01<00:02,  4.02it/s]\u001b[A\n",
            " 47% 9/19 [00:02<00:02,  3.97it/s]\u001b[A\n",
            " 53% 10/19 [00:02<00:02,  3.94it/s]\u001b[A\n",
            " 58% 11/19 [00:02<00:02,  3.91it/s]\u001b[A\n",
            " 63% 12/19 [00:02<00:01,  3.90it/s]\u001b[A\n",
            " 68% 13/19 [00:03<00:01,  3.89it/s]\u001b[A\n",
            " 74% 14/19 [00:03<00:01,  3.89it/s]\u001b[A\n",
            " 79% 15/19 [00:03<00:01,  3.88it/s]\u001b[A\n",
            " 84% 16/19 [00:03<00:00,  3.89it/s]\u001b[A\n",
            " 89% 17/19 [00:04<00:00,  3.89it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.24611248075962067, 'eval_pearsonr': 0.9609050341621567, 'eval_runtime': 5.102, 'eval_samples_per_second': 228.735, 'eval_steps_per_second': 3.724, 'epoch': 9.7}\n",
            " 97% 1600/1650 [23:27<00:47,  1.06it/s]\n",
            "100% 19/19 [00:04<00:00,  3.89it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to ./model/checkpoint-1600\n",
            "Configuration saved in ./model/checkpoint-1600/config.json\n",
            "Model weights saved in ./model/checkpoint-1600/pytorch_model.bin\n",
            "Deleting older checkpoint [model/checkpoint-1500] due to args.save_total_limit\n",
            "100% 1650/1650 [24:10<00:00,  1.63it/s]\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./model/checkpoint-1100 (score: 0.9625535705769546).\n",
            "                                       {'train_runtime': 1451.2848, 'train_samples_per_second': 72.357, 'train_steps_per_second': 1.137, 'train_loss': 0.14460775686032845, 'epoch': 10.0}\n",
            "100% 1650/1650 [24:11<00:00,  1.14it/s]\n",
            "Configuration saved in ./model/config.json\n",
            "Model weights saved in ./model/pytorch_model.bin\n",
            "tokenizer config file saved in ./model/tokenizer_config.json\n",
            "Special tokens file saved in ./model/special_tokens_map.json\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▇▅▆▂▄▃▃▂▃▁▁▂▁▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/pearsonr ▁▁▄▃▆▆▆▆▇▆█▆▇█▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime █▁▂▂▆▁▁▃▆▂▂▄▅▂▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▁█▇▇▃██▆▃▇▇▅▄▇▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▁█▇▇▃██▆▃▇▇▅▄▇▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ██▇▇▆▆▅▅▄▄▃▃▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.24611\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/pearsonr 0.96091\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 5.102\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 228.735\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 3.724\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 10.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 1650\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.0257\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 6385965707893200.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.14461\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 1451.2848\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 72.357\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 1.137\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdaily-tree-21\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/wanted_ai_06/sohn_assign3/runs/3spy8l32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220318_082354-3spy8l32/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[WandB 로깅 기록 바로가기](https://wandb.ai/wanted_ai_06/sohn_assign3/runs/3spy8l32?workspace=user-arc)"
      ],
      "metadata": {
        "id": "TtYHCUugKxyy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 테스트\n"
      ],
      "metadata": {
        "id": "277zYVDJGbIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mv /content/klue-sts-v1.1.tar.gz /content/model/klue-sts-v1.1.tar.gz"
      ],
      "metadata": {
        "id": "UdwEwMRlNPPk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#학습한 모델을 이용하여 dev_set 예측값 출력(real_label)\n",
        "!python /content/Assignment-03/code/inference.py --test_filename \"/content/klue-sts-v1.1/klue-sts-v1.1_dev.json\" --output_dir \"/content\"  --model_tar_file \"klue-sts-v1.1.tar.gz\""
      ],
      "metadata": {
        "id": "rQrt5TtqGDak"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#valid의 label 값을 추출\n",
        "valid_data=read_json('/content/klue-sts-v1.1/klue-sts-v1.1_dev.json')\n",
        "valid_label=[data['labels']['binary-label'] for data in valid_data]\n",
        "\n",
        "\n",
        "#Regression pred 를 binary-label pred로 변환 후 혼동 행렬 및 f1_score 시각화\n",
        "df_pred = pd.read_csv('/content/output.csv',header=None)\n",
        "\n",
        "pred=(df_pred>2.5).astype(int)\n",
        "print(\"epochs 10 / >2.5\")\n",
        "print(classification_report(valid_label, pred))\n",
        "print('custom_model(roberta-base) f1_score:',f1_score(valid_label, pred), end='\\n\\n')\n",
        "\n",
        "pred=(df_pred>3).astype(int)\n",
        "print(\"epochs 10 / >3\")\n",
        "print(classification_report(valid_label, pred))\n",
        "print('custom_model(roberta-base) f1_score:',f1_score(valid_label, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rck0PPfDMIW1",
        "outputId": "35cbaa84-29b3-4bb0-8bb2-a3d38a36cb35"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epochs 10 / >2.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.69      0.81       299\n",
            "           1       0.70      1.00      0.82       220\n",
            "\n",
            "    accuracy                           0.82       519\n",
            "   macro avg       0.85      0.84      0.82       519\n",
            "weighted avg       0.87      0.82      0.82       519\n",
            "\n",
            "custom_model(roberta-base) f1_score: 0.8217636022514071\n",
            "\n",
            "epochs 10 / >3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.79      0.86       299\n",
            "           1       0.77      0.95      0.85       220\n",
            "\n",
            "    accuracy                           0.86       519\n",
            "   macro avg       0.86      0.87      0.86       519\n",
            "weighted avg       0.87      0.86      0.86       519\n",
            "\n",
            "custom_model(roberta-base) f1_score: 0.8478701825557808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dev_set에 대한 pearsonr score 출력 \n",
        "df_pred = pd.read_csv('/content/output.csv',header=None)\n",
        "valid_data=read_json('/content/klue-sts-v1.1/klue-sts-v1.1_dev.json')\n",
        "valid_label=[data['labels']['real-label'] for data in valid_data]\n",
        "\n",
        "pearson = load_metric(\"pearsonr\").compute\n",
        "metric = pearson(predictions=df_pred.to_numpy(), references=valid_label)\n",
        "print(metric)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PQwca9tMUCT",
        "outputId": "acf5c05c-1529-49f9-c9f3-290564882564"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pearsonr': 0.8869273898083346}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 성능 비교\n",
        "\n",
        "|모델 특징|전처리 유무|dev peasonr score|dev f1 score|\n",
        "|:---|:---:|:---:|:---:|\n",
        "|base|X|~ 0.894|~ 0.859|\n",
        "|custom|X|~ 0.898|~ 0.864|\n",
        "|custom|영어, 숫자, 특수문자 전처리|0.847|0.835|\n",
        "|custom|영어만 소문자 처리|0.808|0.823|\n",
        "\n",
        "전처리를 통한 성능 감소를 확인 하였고 전처리를 진행하지 않고 학습시킨 custom 모델을 최종 선정하였습니다."
      ],
      "metadata": {
        "id": "C6R1FF5sMZCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "YuFNSM4Wa2B5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "B7Ig20YLazFq"
      }
    }
  ]
}
